# 计算机系统

- 硬中断和软中断是什么  
答：在计算机系统中，CPU只负责执行程序指令，当他开始运行一个程序，如果程序本身没有错误，并且外部不加干预，CPU将会一直把这个程序执行完。
但现代计算机运行过程中有很多进程要分时运行，也就是每个进程只能执行一小段时间，然后就要换其他进程执行，这个调度是OS负责的；
同时，对于一些外部事件，诸如断电、鼠标/键盘点击、磁盘可以读写、网络有新的数据到达等，OS要能够及时得知并进行响应处理；
简单的说就是OS需要能够控制什么时间运行什么指令。  
中断是CPU提供给OS内核的接口（或者说是会调），外部设备或正在运行的程序本身都可以产生中断，
CPU每执行完一条指令，就检查当前是否有中断产生，如果有，就调用相关的中断处理程序，在中断处理程序对该事件进行处理，
比如timer中断处理程序可以调用OS的schedule进行进程调度。
中断大概可以有三类：interrupt、exception、trap。其中interrupt就是我们常说的硬中断，是由外部硬件产生的；exception是运行异常，
比如除以0，内存缺页等；trap是执行某些特殊指令会自动陷入OS，比如sys_call等。  
需要注意的是，中断处理程序的执行时间是越短越好，因为中断被handle的期间，CPU不能接收其他中断（理论上中断可以嵌套handle，但太复杂，Linux2.6.3以后不再支持）
但是有些事件的handle处理是比较复杂的，比如网络包的接收，需要经过TCP/IP协议栈的层层处理。为了解决这个问题，OS将中断handle步骤分为TOP HALF和bottom half，
其中TOP half尽早结束，结束后就再次开启接收CPU中断；bottom half异步线程执行，Linux中常见的bottom half实现有三种：softirq, tasklet, workqueue。
很多人把这个bottom half称作软中断，相对TOP half来说，确实比较"软"。  
在OS中，signal也常被称作软中断。signal是内核发给其他进程的一种异步消息，目标进程可以事先实现消息处理器。和硬中断不同，signal一定是正在执行的内核程序产生的，
并且不会立即中断CPU的执行序列，而是要等到OS正常schedule到一个新进程之前，OS检查是否有发送到目标进程的signal，如果有，就让目标进程执行响应handle。可见这种
异步通知机制也是比较"软"的。

- stack overflow是如何发生的  
答：程序执行时，需要把调用方法的参数、返回地址、局部变量压栈，每执行完一个局部方法，将该方法相关变量出栈；
stack是有限的（java中通过XSS设置），如果调用层次比较深（比如递归），局部变量比较大，就容易发生stack overflow。



# 并发

- 并发写同一个socket，file会怎样  
答：主要取决于是否共享同一个FD, 如果共享，这没问题，如果没有共享，会导致数据被覆盖。

- 同一个进程的不同线程如何通信  
答：socket、共享内存、共享文件、信号（取决于OS提供的能力）

- OS中线程管理相关的数据结构  
    * thread queue for schedule： blocked threads、ready threads、running thread
    * thread.fds、thread.locks、thread.TCB

- OS提供哪些线程相关系统调用  
    pthread_cond_broadcast [pthread_cond_init] - operations on conditions
    pthread_cond_destroy [pthread_cond_init] - operations on conditions
    pthread_cond_init - operations on conditions
    pthread_cond_signal [pthread_cond_init] - operations on conditions
    pthread_cond_timedwait [pthread_cond_init] - operations on conditions
    pthread_cond_wait [pthread_cond_init] - operations on conditions
    pthread_create - create a new thread
    pthread_detach - put a running thread in the detached state
    pthread_exit - terminate the calling thread
    pthread_join - wait for termination of another thread
    pthread_mutex_destroy [pthread_mutex_init] - operations on mutexes
    pthread_mutex_init - operations on mutexes
    pthread_mutex_lock [pthread_mutex_init] - operations on mutexes
    pthread_mutex_trylock [pthread_mutex_init] - operations on mutexes
    pthread_mutex_unlock [pthread_mutex_init] - operations on mutexes


# I/O

- Linux top命令显示的buffer和cache具体指什么  


- zero copy是什么，哪些开源软件有应用？  
To understand the impact of sendfile, it is important to understand the common data path for transfer of data from file to socket:
    * The operating system reads data from the disk into pagecache in kernel space
    * The application reads the data from kernel space into a user-space buffer
    * The application writes the data back into kernel space into a socket buffer
    * The operating system copies the data from the socket buffer to the NIC buffer where it is sent over the network

This is clearly inefficient, there are four copies and two system calls. 
Using sendfile, this re-copying is avoided by allowing the OS to send the data from pagecache to the network directly. 
So in this optimized path, only the final copy to the NIC buffer is needed.

所谓zero copy并不是真的"零"拷贝，而是user space视角的零拷贝，整个过程免了CPU参与的copy，节约零内存带宽和CPU cycle、CPU cache。  
有数据存取功能到网络服务软件都有应用，比如Kafka、tomcat。

https://man7.org/linux/man-pages/man2/sendfile.2.html
https://xunnanxu.github.io/2016/09/10/It-s-all-about-buffers-zero-copy-mmap-and-Java-NIO/
https://www.linuxjournal.com/article/6345?page=0,0

- 常见的网络IO模型及其特点  
      * blocked IO, one thread per socket, has C10K problem
      * non-blocked IO, should check interval
      * I/O multiplexing, blocked at select system call, advance is select can listen more than one socket.
      * signal driven I/O (SIGIO)
      * asynchronous I/O (the POSIX aio_ functions)
      
  POSIX defines these two terms as follows:
  
  A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes.  
  An asynchronous I/O operation does not cause the requesting process to be blocked.  
  Using these definitions, the first four I/O models (blocking, nonblocking, I/O multiplexing, and signal-driven I/O) are all synchronous because the actual I/O operation (recvfrom) blocks the process. Only the asynchronous I/O model matches the asynchronous I/O definition.



# network
- 简述TCP三次握手，为什么不是两次或四次  
答：A->B: SYNC; B->A: SYNC, ACK; A->B: ACK; 因为三次正好AB都收到自己发送的消息的回应，确认了对方同意连接并且有收发能力。
在A所送最后但ACK之后，B收到ACK之前，此时的连接状态是A自认为成功，B自认为未成功。此时A已经可以给B发送消息。

- 简述TCP四次挥手  
答：A->B: CLOSE; B->A: ACK; （稍后）B->A: CLOSE; A->B: ACK; 之所以需要四次是因为连接已经建立且是双工的，
需要两边都确认断开。另外值得注意的是首先发起挥手的一端在发送完最后的ACK后，需要一个2倍路由时间的TIME_WAIT,
防止确保ACK能够到达对端，同时确保当前连接发送的消息都消失在TTL的线路中，不会被当作下一次连接的数据包。

- TCP 慢启动是为了什么目的，怎么实现的  
答：发送端每次可以发送最大报文数是MIN(发送端拥塞窗口，接受端滑动窗口）。TCP连接建立之后，发送端拥塞窗口大小为1，
然后如果通信正常，再倍数增大。为了是防止网络拥塞，因为一开始的时候不知道网络情况怎么样。

- TCP 快重传是什么，为了解决什么问题  
答：当消息发送端发现消息ACK超时，会认为此时的发送苏打绿已经达到网络极限，这是需要缩小自身的拥塞窗口大小，
一种做法是重置拥塞窗口为1，然后重新执行满启动，但这种做法有些浪费带宽，快重传的思路是将拥塞窗口减半，并且线性递增，
这样可以更快的适应网络情况，避免不必要的浪费。

- TCP 滑动窗口如何实现的  
答：滑动窗口机制可以让发送端根据接受端的接受能力动态调整发送速率，保证接受端不会因为超负荷而丢失消息。
在操作系统中，每个socket有两个buffer：recv buffer和send buffer，滑动窗口就是recv buffer的可写空间大小。
OS每次响应发送端报文时，告知对应socket recv buffer的可写空间大小作为接受窗口大小。当该窗口大小为0时，
发送端将停止发送数据，同时OS内核线程定时轮训接受端，检测窗口是否变化。

- SO_RCVBUF、SO_SNDBUF是什么，在linux上如何查看  
答：建立socket时的option，分别代表接收队列和发送队列的大小。每个socket可以独立设置，可选，Linux系统有默认值。
可以使用netstat命令查看系统当前socket的BUFFER使用情况。值得一提的是这个窗口在OS里可以实现滑动窗口机制。  
另外，send(), read()方法操作的就是这个buffer，且只是这个buffer。意思是send()方法将要发送的数据放到这个buffer就返回了，
不代表数据已经发送到对端（OS线程负责发送，重传，删除已确认数据等）。至于阻塞和非阻塞的send，差异只是表现在写SO_SNDBUF时，
如果空间不够，一个要阻塞等待，一个不需要，能写多少写多少。

- socket 发送队列和对端接受队列一样大吗？  
答：不一样大，这两个队列相互之间独立不影响对方。队列的最大长度取决于socket设置，实时可读写长度取决于用户进程的消费速度。
接受列队的可写空间大小即为其ACK的滑动窗口大小，当这个窗口变小，会导致发送端的发送速度降低，准确的说是发送端
内核协议栈线程的处理速度降低，大量数据缓存在sk_buff和socket发送队列，但发送队列的总大小和实时可用大小都不是与接收方相同的。

- TCP keepalive(SO_KEEPALIVE) 是什么，http keepalive呢  
答：当TCP连接很久没有活动的时候，是不是要发送给心跳包，检测连接是否存活，如果连接已经异常断开，可以释放系统资源。
有三个相关参数可以配置：  
tcp_keepalive_time：最后一个数据包发送完毕和第一个心跳包发送的最大间隔时间  
tcp_keepalive_intvl：第一个心跳包发送后，每个多少秒发送下一个心跳包  
tcp_keepalive_probes：连续多少个心跳包没有收到响应算作连接失效  
HTTP Keep-Alive 是http header中的一个字段，用来表示该http连接是否需要keep open供后续使用，可以使用timeout和max两个参数设置keep-open的策略，
需要注意的是最大open time不可能超过底层TCP的最大时间（比如底层TCP没有设置keepalive）  

- SO_LINGER 是什么  
答：SO_LINGER: 延时关闭。当开启的时候，调用socket close()方法时需要等待尚未发送完毕的数据发送完毕或者延时时间超时，才会close。  

- Nagle's Algorithm, TCP_NODELAY, Delayed ACK and TCP_QUICKACK  
答：
    * Nagle's Algorithm：一种通过合并小包发送，提高data:header有效数据比例，提高网络通信效率的算法；  
    * Delayed ACK：ACK是小包并且比较频繁，应该减少ACK的发送次数，因为ACK是有序号的，所以可以累计确认；需要注意的是Nagle和DelayACK有些冲突，因为Nagle等待接收ACK来确定更多的可发送内容；而DelayACK尝试晚一些发送ACK;   
    * TCP_NODELAY：socket参数，表示禁用Nagle算法
    * TCP_QUICKACK：socket参数，表示禁用DelayACK算法

- 为什么SYNC 攻击会导致网络瘫痪，但是CPU负载却不高  
答：sync数据包送达服务器网卡后，网卡通过DMA将数据包存放在网卡接受队列（ring buffer, 存放的是sk_buff的指针），然后发起硬中断通知内核，
接着网卡driver提前注册到内核的处理程序会被唤起执行，分为上下两个阶段，top-half很快返回，在bottom-half阶段（异步内核线程）按TCP/IP协议栈规范解析该数据包。
当发现是一个尝试建立连接的SYNC时，根据TCP协议响应一个SYNC+ACK，同时在half-open队列中维护一个半开的连接，当收到client最终的ACK后，
再将该连接move到established队列，然后等待用户进程使用accept系统调用获取该socket。  
问题在于SYNC攻击不会有后续的ACK，这样很快便会耗尽服务器的half-open队列（这个队列应该有超时自动丢弃的机制），使得服务器不能接受新的握手请求；
同时，CPU不高可能是因为bottom-half阶段的异步内核线程的优先级不高且执行时间有限制，不会占满CPU（不然可能导致正常情况下时用户线程饿死的情况）。

- 多个应用层请求会放到同一个IP报文发送吗  
答： 同一个socket链接的多个请求应该会，用户线程只是根据应用层协议将请求数据写入 SO_SNDBUF, 
将数据按TCP/IP协议封装然后通知网卡是由OS线程异步处理的，同一个 SO_SNDBUF 中的数据都是发往同一地址，
所以OS线程应该不会区分对待这些数据，同一按MTU发给网卡了（也不能区分，这需要依赖应用层协议细节）不同链接的请求不会，因为TCP/IP头都不一样。


# 性能指标
- memcached单个节点的读写上限是多少
- mysql简单读写TPS上限
- 机械硬盘顺序读写上限    50M values/s
- 机械硬盘随机读写上限    300 values/s
- SSD顺序读写上限         40M values/s
- SSD随机读写上限         2K values/s